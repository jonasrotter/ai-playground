{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5b29d1",
   "metadata": {},
   "source": [
    "# Multi-Agent Orchestration with OpenAI Agents SDK: Financial Portfolio Analysis Example\n",
    "\n",
    "## Introduction\n",
    "\n",
    "*This guide is for readers already familiar with OpenAI models and LLM agents, and want to see how to orchestrate a team of agents for a real-world, complex task.*\n",
    "\n",
    "**What You'll Learn**\n",
    "\n",
    "In this notebook, you'll learn how to use the OpenAI Agents SDK to design and implement a complex multi-agent collaboration system. Specifically, you'll see how to:\n",
    "- Build a workflow where multiple specialist agents (Macro, Fundamental, Quantitative) collaborate under a Portfolio Manager agent to solve a challenging investment research problem.\n",
    "- Use the \"agents as a tool\" approach, where a central agent orchestrates and calls other agents as tools for specific subtasks.\n",
    "- Leverage all major tool types supported by the SDK (custom Python functions, managed tools like Code Interpreter and WebSearch, and external MCP servers) in a single, integrated workflow.\n",
    "- Apply best practices for modularity, parallelism, and observability in agentic patterns.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "The \"agents as a tool\" pattern is a powerful way to build transparent, auditable, and scalable multi-agent collaboration . This example demonstrates how to combine deep specialization, parallel execution, and robust orchestration using the OpenAI Agents SDK.\n",
    "\n",
    "By the end of this guide, you'll have a clear blueprint for building your own multi-agent workflows for research, analysis, or any complex task that benefits from expert collaboration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed547489",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is Multi-Agent Collaboration?](#what-is-multi-agent-collaboration)\n",
    "2. [Collaboration Patterns: Handoff vs. Agent-as-Tool](#collaboration-patterns-handoff-vs-agent-as-tool)\n",
    "3. [Architecture Overview](#architecture-overview)\n",
    "4. [Supported Tool Types](#supported-tool-types)\n",
    "5. [Setup](#setup)\n",
    "6. [Running the Workflow](#running-the-workflow)\n",
    "7. [The Head Portfolio Manager (PM) Agent](#the-head-portfolio-manager-pm-agent)\n",
    "8. [Breaking Down the Head Portfolio Manager Agent](#breaking-down-the-head-portfolio-manager-agent)\n",
    "9. [Example Output](#example-output)\n",
    "10. [Best Practices When Building Agents](#best-practices-when-building-agents)\n",
    "11. [Further Reading & Best Practices](#further-reading--best-practices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26670dad",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## What is Multi-Agent Collaboration?\n",
    "\n",
    "**Multi-agent collaboration** means multiple autonomous agents (LLM \"nodes\") coordinate to achieve an overarching goal that would be difficult for a single agent to handle. Instead of one monolithic prompt, each agent handles a specific subtask or expertise area, and an orchestration layer connects these agent \"nodes\" into a coherent workflow. This approach is useful for complex systems â€“ for example, a financial analysis might be broken into macro-economic analysis, fundamental company analysis, and quantitative signal analysis, each handled by a different agent specialist. The agents share information and their results are combined to produce a final outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f3a58",
   "metadata": {},
   "source": [
    "\n",
    "### Collaboration Patterns: Handoff vs. Agent-as-Tool\n",
    "\n",
    "The OpenAI Agents SDK supports multiple patterns for agents to work together:\n",
    "\n",
    "- **Handoff Collaboration:** One agent can _handoff_ control to another agent mid-problem. In a handoff architecture, each agent knows about the others and can decide when to defer to a more appropriate agent. This is flexible for open-ended or conversational workflows, but can make it harder to maintain a global view of the task. [Read more in the SDK docs.](https://openai.github.io/openai-agents-python/handoffs/)\n",
    "\n",
    "- **Agent as a Tool:** In this approach, one agent (often a central planner or manager) **calls other agents as if they were tools**. Sub-agents don't take over the conversation; instead, the main agent invokes them for specific subtasks and incorporates their results. This model keeps a single thread of control (the main agent orchestrates everything) and tends to simplify coordination. **This repo uses the agent-as-tool model:** the Portfolio Manager agent remains in charge, using the other specialist agents as tools when it needs their expertise. This choice keeps the overall reasoning transparent and allows parallel execution of sub-tasks, which is ideal for complex analyses.\n",
    "\n",
    "For more on these collaboration patterns, see the [OpenAI Agents SDK documentation](https://openai.github.io/openai-agents-python/multi_agent/).\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "Our system follows a **hub-and-spoke design**. The **Portfolio Manager agent** is the hub (central coordinator), and the **specialist agents** are the spokes. The user's query (e.g. \"How would a planned interest rate reduction affect my GOOGL holdings?\") goes first to the Portfolio Manager. The Portfolio Manager agent is prompted to break down the problem and delegate to the appropriate specialist agents. It treats each specialist as a callable tool, invoking them for their portion of the analysis. All three report back to the Portfolio Manager, which then synthesizes a final answer for the user.\n",
    "\n",
    "![Multi-Agent Investment Report Workflow](../../../images/multi_agent_collab_agent_architecture.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2ef1e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Supported Tool Types\n",
    "\n",
    "A key advantage of the Agents SDK is the flexibility in defining **tools** that agents can use. Tools can range from simple Python functions to external services. In this project, we use:\n",
    "\n",
    "- **MCP (Model Context Protocol) Server:** Used to connect agents to external tools and data sources in a standardized way. This project uses a local MCP server for Yahoo Finance data (see `mcp/yahoo_finance_server.py`). [Learn more: OpenAI MCP docs](https://openai.github.io/openai-agents-python/mcp/) | [MCP Spec](https://modelcontextprotocol.io/)\n",
    "\n",
    "- **OpenAI Managed Tools:** Managed tools are built-in, hosted tools provided by OpenAI that require no custom implementation. They offer powerful capabilities out of the box, such as **Code Interpreter** (for quantitative/statistical analysis) and **WebSearch** (for up-to-date news and data). These tools are easy to integrate, maintained by OpenAI, and allow agents to perform advanced actions like code execution and real-time information retrieval without additional setup.\n",
    "\n",
    "- **Custom Tools:** Custom tools are any Python functions you define and register as tools for your agent. The Agents SDK makes this easy: just decorate your function, and the SDK will automatically extract its name, docstring, and input schema. This is ideal for domain-specific logic, data access, or workflow extensions. \n",
    "  In our project, we use custom tools to access FRED economic data ([see FRED API](https://fred.stlouisfed.org/docs/api/api_key.html)) and perform file system operations.\n",
    "\n",
    "Custom tools give you full flexibility to extend your agent's capabilities beyond built-in or managed tools. [See the SDK docs on function tools.](https://openai.github.io/openai-agents-python/tools/#function-tools)\n",
    "\n",
    "> **Want to add more tools?** The SDK supports a wide range of tool types, including web search, file search, code execution, and more. [See the full list of supported tools in the SDK documentation.](https://openai.github.io/openai-agents-python/tools/)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc589749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2f377",
   "metadata": {},
   "source": [
    "**Before running the workflow, set your environment variables:**\n",
    "- `OPENAI_API_KEY` (for OpenAI access)\n",
    "- `FRED_API_KEY` (for FRED economic data, see [FRED API key instructions](https://fred.stlouisfed.org/docs/api/api_key.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70bf2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required API keys are set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "missing = []\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    missing.append('OPENAI_API_KEY')\n",
    "if not os.environ.get('FRED_API_KEY'):\n",
    "    missing.append('FRED_API_KEY')\n",
    "\n",
    "if missing:\n",
    "    print(f\"Missing environment variable(s): {', '.join(missing)}. Please set them before running the workflow.\")\n",
    "else:\n",
    "    print(\"All required API keys are set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2c4e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Running the Workflow \n",
    "\n",
    "Edit the question to whatever you'd like, but keep the date field to improve accuracy!\n",
    "\n",
    "<div style=\"border-left: 4px solidrgb(0, 0, 0); padding: 0.5em; background:rgb(255, 229, 229);\">\n",
    "<strong>Disclaimer:</strong> This example is for educational purposes only. Consult a qualified financial professional before making any investment decisions\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b11e29",
   "metadata": {},
   "source": [
    "The workflow is kicked off by sending a user request to the Head Portfolio Manager (PM) agent. The PM agent orchestrates the entire process, delegating to specialist agents and tools as needed. You can monitor the workflow in real time using OpenAI Traces, which provide detailed visibility into every agent and tool call.\n",
    "\n",
    "Edit the `question` in the code below to whatever you'd like, but keep the date field to improve accuracy!\n",
    "\n",
    "<div style=\"border-left: 4px solid #f39c12; padding: 0.5em; background: #fffbe6;\">\n",
    "<strong>Note:</strong> Depending on the complexity of the task, this request can take up to 10 minutes.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7059b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from contextlib import AsyncExitStack\n",
    "from agents import Runner, add_trace_processor, trace\n",
    "from agents.tracing.processors import BatchTraceProcessor\n",
    "from utils import FileSpanExporter, output_file\n",
    "from investment_agents.config import build_investment_agents\n",
    "import asyncio\n",
    "\n",
    "add_trace_processor(BatchTraceProcessor(FileSpanExporter()))\n",
    "\n",
    "async def run_workflow():\n",
    "    if \"OPENAI_API_KEY\" not in os.environ:\n",
    "        raise EnvironmentError(\"OPENAI_API_KEY not set â€” set it as an environment variable before running.\")\n",
    "\n",
    "    today_str = datetime.date.today().strftime(\"%B %d, %Y\")\n",
    "    question = (\n",
    "        f\"Today is {today_str}. \"\n",
    "        \"How would the planned interest rate reduction effect my holdings in GOOGL if they were to happen?\"\n",
    "        \"Considering all the factors effecting its price right now (Macro, Technical, Fundamental, etc.), what is a realistic price target by the end of the year?\"\n",
    "    )\n",
    "    bundle = build_investment_agents()\n",
    "\n",
    "    async with AsyncExitStack() as stack:\n",
    "        for agent in [getattr(bundle, \"fundamental\", None), getattr(bundle, \"quant\", None)]:\n",
    "            if agent is None:\n",
    "                continue\n",
    "            for server in getattr(agent, \"mcp_servers\", []):\n",
    "                await server.connect()\n",
    "                await stack.enter_async_context(server)\n",
    "\n",
    "        print(\"Running multi-agent workflow with tracing enabled...\\n\")\n",
    "        with trace(\n",
    "            \"Investment Research Workflow\",\n",
    "            metadata={\"question\": question[:512]}\n",
    "        ) as workflow_trace:\n",
    "            print(\n",
    "                f\"\\nðŸ”— View the trace in the OpenAI console: \"\n",
    "                f\"https://platform.openai.com/traces/trace?trace_id={workflow_trace.trace_id}\\n\"\n",
    "            )\n",
    "\n",
    "            response = None\n",
    "            try:\n",
    "                response = await asyncio.wait_for(\n",
    "                    Runner.run(bundle.head_pm, question, max_turns=40),\n",
    "                    timeout=1200\n",
    "                )\n",
    "            except asyncio.TimeoutError:\n",
    "                print(\"\\nâŒ Workflow timed out after 20 minutes.\")\n",
    "\n",
    "            report_path = None\n",
    "            try:\n",
    "                if hasattr(response, 'final_output'):\n",
    "                    output = response.final_output\n",
    "                    if isinstance(output, str):\n",
    "                        data = json.loads(output)\n",
    "                        if isinstance(data, dict) and 'file' in data:\n",
    "                            report_path = output_file(data['file'])\n",
    "            except Exception as e:\n",
    "                print(f\"Could not parse investment report path: {e}\")\n",
    "\n",
    "            print(f\"Workflow Completed Response from Agent: {response.final_output if hasattr(response, 'final_output') else response}, investment report created: {report_path if report_path else '[unknown]'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18c7886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error initializing MCP server: fileno\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "fileno",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnsupportedOperation\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\mcp\\client\\stdio\\win32.py:138\u001b[39m, in \u001b[36mcreate_windows_process\u001b[39m\u001b[34m(command, args, env, errlog, cwd)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# Try launching with creationflags to avoid opening a new console window\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     popen_obj = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unbuffered output\u001b[39;49;00m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCREATE_NO_WINDOW\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FallbackProcess(popen_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\subprocess.py:1005\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;66;03m# Input and output objects. The general principle is like\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;66;03m# this:\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1000\u001b[39m \u001b[38;5;66;03m# are -1 when not using PIPEs. The child objects are -1\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[38;5;66;03m# when not redirecting.\u001b[39;00m\n\u001b[32m   1003\u001b[39m (p2cread, p2cwrite,\n\u001b[32m   1004\u001b[39m  c2pread, c2pwrite,\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m  errread, errwrite) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[38;5;66;03m# From here on, raising exceptions may cause file descriptor leakage\u001b[39;00m\n\u001b[32m   1008\u001b[39m \n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# We wrap OS handles *before* launching the child, otherwise a\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# quickly terminating child could make our fds unwrappable\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# (see #8458).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\subprocess.py:1422\u001b[39m, in \u001b[36mPopen._get_handles\u001b[39m\u001b[34m(self, stdin, stdout, stderr)\u001b[39m\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1421\u001b[39m     \u001b[38;5;66;03m# Assuming file-like object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m     errwrite = msvcrt.get_osfhandle(\u001b[43mstderr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1423\u001b[39m errwrite = \u001b[38;5;28mself\u001b[39m._make_inheritable(errwrite)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\ipykernel\\iostream.py:371\u001b[39m, in \u001b[36mOutStream.fileno\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    370\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mfileno\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m io.UnsupportedOperation(msg)\n",
      "\u001b[31mUnsupportedOperation\u001b[39m: fileno",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnsupportedOperation\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# In a Jupyter notebook cell, run:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_workflow()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mrun_workflow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m server \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(agent, \u001b[33m\"\u001b[39m\u001b[33mmcp_servers\u001b[39m\u001b[33m\"\u001b[39m, []):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m server.connect()\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m stack.enter_async_context(server)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning multi-agent workflow with tracing enabled...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\agents\\mcp\\server.py:209\u001b[39m, in \u001b[36m_MCPServerWithClientSession.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Connect to the server.\"\"\"\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     transport = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_stack.enter_async_context(\u001b[38;5;28mself\u001b[39m.create_streams())\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# streamablehttp_client returns (read, write, get_session_id)\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;66;03m# sse_client returns (read, write)\u001b[39;00m\n\u001b[32m    213\u001b[39m     read, write, *_ = transport\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\contextlib.py:668\u001b[39m, in \u001b[36mAsyncExitStack.enter_async_context\u001b[39m\u001b[34m(self, cm)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    666\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot support the asynchronous context manager protocol\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    667\u001b[39m                    ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m668\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m _enter(cm)\n\u001b[32m    669\u001b[39m \u001b[38;5;28mself\u001b[39m._push_async_cm_exit(cm, _exit)\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\contextlib.py:214\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py:115\u001b[39m, in \u001b[36mstdio_client\u001b[39m\u001b[34m(server, errlog)\u001b[39m\n\u001b[32m    112\u001b[39m     command = _get_executable_command(server.command)\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Open process with stderr piped for capture\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     process = \u001b[38;5;28;01mawait\u001b[39;00m _create_platform_compatible_process(\n\u001b[32m    116\u001b[39m         command=command,\n\u001b[32m    117\u001b[39m         args=server.args,\n\u001b[32m    118\u001b[39m         env=({**get_default_environment(), **server.env} \u001b[38;5;28;01mif\u001b[39;00m server.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m get_default_environment()),\n\u001b[32m    119\u001b[39m         errlog=errlog,\n\u001b[32m    120\u001b[39m         cwd=server.cwd,\n\u001b[32m    121\u001b[39m     )\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# Clean up streams if process creation fails\u001b[39;00m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m read_stream.aclose()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py:224\u001b[39m, in \u001b[36m_create_platform_compatible_process\u001b[39m\u001b[34m(command, args, env, errlog, cwd)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03mCreates a subprocess in a platform-compatible way.\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03mReturns a process handle.\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     process = \u001b[38;5;28;01mawait\u001b[39;00m create_windows_process(command, args, env, errlog, cwd)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     process = \u001b[38;5;28;01mawait\u001b[39;00m anyio.open_process([command, *args], env=env, stderr=errlog, cwd=cwd)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\mcp\\client\\stdio\\win32.py:152\u001b[39m, in \u001b[36mcreate_windows_process\u001b[39m\u001b[34m(command, args, env, errlog, cwd)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FallbackProcess(popen_obj)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# If creationflags failed, fallback without them\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     popen_obj = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FallbackProcess(popen_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\subprocess.py:1005\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser ID cannot be negative, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    988\u001b[39m \u001b[38;5;66;03m# Input and output objects. The general principle is like\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;66;03m# this:\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1000\u001b[39m \u001b[38;5;66;03m# are -1 when not using PIPEs. The child objects are -1\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[38;5;66;03m# when not redirecting.\u001b[39;00m\n\u001b[32m   1003\u001b[39m (p2cread, p2cwrite,\n\u001b[32m   1004\u001b[39m  c2pread, c2pwrite,\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m  errread, errwrite) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[38;5;66;03m# From here on, raising exceptions may cause file descriptor leakage\u001b[39;00m\n\u001b[32m   1008\u001b[39m \n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# We wrap OS handles *before* launching the child, otherwise a\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# quickly terminating child could make our fds unwrappable\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# (see #8458).\u001b[39;00m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _mswindows:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\subprocess.py:1422\u001b[39m, in \u001b[36mPopen._get_handles\u001b[39m\u001b[34m(self, stdin, stdout, stderr)\u001b[39m\n\u001b[32m   1419\u001b[39m         errwrite = msvcrt.get_osfhandle(stderr)\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1421\u001b[39m         \u001b[38;5;66;03m# Assuming file-like object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m         errwrite = msvcrt.get_osfhandle(\u001b[43mstderr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1423\u001b[39m     errwrite = \u001b[38;5;28mself\u001b[39m._make_inheritable(errwrite)\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (p2cread, p2cwrite,\n\u001b[32m   1426\u001b[39m         c2pread, c2pwrite,\n\u001b[32m   1427\u001b[39m         errread, errwrite)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jonasrotter\\Desktop\\Demos\\ai-playground\\playgroundenv\\Lib\\site-packages\\ipykernel\\iostream.py:371\u001b[39m, in \u001b[36mOutStream.fileno\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._original_stdstream_copy\n\u001b[32m    370\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mfileno\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m io.UnsupportedOperation(msg)\n",
      "\u001b[31mUnsupportedOperation\u001b[39m: fileno"
     ]
    }
   ],
   "source": [
    "# In a Jupyter notebook cell, run:\n",
    "await run_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94273ca6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Breaking Down the Head Portfolio Manager Agent\n",
    "\n",
    "The Head Portfolio Manager (PM) agent is the orchestrator of the entire workflow. It coordinates a set of four specialist agents, each focused on a different area of expertise. This design is intentional: overloading a single agent with every possible responsibility leads to shallow, generic outputs and makes it hard to maintain or improve your system over time.\n",
    "\n",
    "### Why This Design?\n",
    "By breaking the problem into specialized agentsâ€”each with a clear roleâ€”you get:\n",
    "\n",
    "- **Deeper, higher-quality research:** Each agent can focus on its domain, using the right tools and prompts for the job. The PM agent brings these perspectives together for a more nuanced, robust answer.\n",
    "\n",
    "- **Modularity and clarity:** You can update, test, or improve one agent without affecting the others. This makes your system easier to maintain and extend as your needs evolve.\n",
    "\n",
    "- **Faster results through parallelism:** Independent agents can work at the same time, dramatically reducing the time to complete complex, multi-part analyses.\n",
    "\n",
    "- **Consistency and auditability:** A structured, prompt-driven workflow ensures every run follows best practices, is easy to debug, and produces outputs you can trust and review.\n",
    "\n",
    "This approach is ideal for any application where you want depth, specialization, and reliabilityâ€”whether you're building a research assistant, a decision support tool, or any system that benefits from expert collaboration and orchestration.\n",
    "\n",
    "**How We Implement This in Practice:**\n",
    "- Each specialist agent (Fundamental, Macro, Quantitative) is wrapped as a callable tool using the SDK's `function_tool` decorator, with custom names and descriptions. This makes the PM agent's toolset explicit and LLM-friendly.\n",
    "\n",
    "- The Head PM agent uses the `run_all_specialists_parallel` tool to invoke all three specialists concurrently, leveraging `parallel_tool_calls=True` for maximum speed and efficiency.\n",
    "\n",
    "- The agent's prompt is loaded from a markdown file (`pm_base.md`), encoding not just the firm's philosophy but also detailed tool usage rules and a step-by-step workflow. This ensures every run is consistent, auditable, and aligned with best practices.\n",
    "\n",
    "- After gathering and reviewing the specialist outputs, the PM agent uses a dedicated memo editor tool to assemble, format, and finalize the investment report. This separation of concerns keeps the workflow modular and easy to extend.\n",
    "\n",
    "- The system is designed for extensibility: you can add new specialist agents, swap out tools, or update prompts without breaking the overall orchestration logic. All tool calls, agent decisions, and outputs are captured in OpenAI Traces for full transparency and debugging.\n",
    "\n",
    "These implementation choices directly support the benefits aboveâ€”enabling deep, modular, and reliable multi-agent research workflows that are easy to maintain, audit, and improve.\n",
    "\n",
    "### Head Portfolio Manager Agent: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c464a",
   "metadata": {},
   "source": [
    "```python\n",
    "from agents import Agent, ModelSettings, function_tool\n",
    "from utils import load_prompt, DISCLAIMER\n",
    "\n",
    "def build_head_pm_agent(fundamental, macro, quant, memo_edit_tool):\n",
    "    def make_agent_tool(agent, name, description):\n",
    "        @function_tool(name_override=name, description_override=description)\n",
    "        async def agent_tool(input):\n",
    "            return await specialist_analysis_func(agent, input)\n",
    "        return agent_tool\n",
    "    fundamental_tool = make_agent_tool(fundamental, \"fundamental_analysis\", \"Generate the Fundamental Analysis section.\")\n",
    "    macro_tool = make_agent_tool(macro, \"macro_analysis\", \"Generate the Macro Environment section.\")\n",
    "    quant_tool = make_agent_tool(quant, \"quantitative_analysis\", \"Generate the Quantitative Analysis section.\")\n",
    "\n",
    "    @function_tool(name_override=\"run_all_specialists_parallel\", description_override=\"Run all three specialist analyses (fundamental, macro, quant) in parallel and return their results as a dict.\")\n",
    "    async def run_all_specialists_tool(fundamental_input, macro_input, quant_input):\n",
    "        return await run_all_specialists_parallel(\n",
    "            fundamental, macro, quant,\n",
    "            fundamental_input, macro_input, quant_input\n",
    "        )\n",
    "\n",
    "    return Agent(\n",
    "        name=\"Head Portfolio Manager Agent\",\n",
    "        instructions=(load_prompt(\"pm_base.md\") + DISCLAIMER),\n",
    "        model=\"gpt-4.1\",\n",
    "        tools=[fundamental_tool, macro_tool, quant_tool, memo_edit_tool, run_all_specialists_tool],\n",
    "        model_settings=ModelSettings(parallel_tool_calls=True, tool_choice=\"auto\", temperature=0)\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908f59c",
   "metadata": {},
   "source": [
    "### The Head PM System Prompt: Enforcing Best Practices\n",
    "\n",
    "The PM agent's system prompt (see `prompts/pm_base.md`) is the heart of the workflow. It encodes:\n",
    "- The firm's philosophy (originality, risk awareness, challenging consensus)\n",
    "- Clear tool usage rules (when to use parallel tools, how to structure inputs)\n",
    "- A robust, multi-step workflow (determine task type, provide guidance, review outputs, assemble memo, handle missing data)\n",
    "\n",
    "This prompt ensures that every run is:\n",
    "- **Consistent:** The same high standards and process are followed every time.\n",
    "- **Auditable:** Each step, tool call, and decision is visible in the trace.\n",
    "- **High-Quality:** Outputs are original, risk-aware, and rigorously reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the actual system prompt used by the Head Portfolio Manager agent\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "pm_prompt_path = Path(\"prompts/pm_base.md\")\n",
    "if pm_prompt_path.exists():\n",
    "    with pm_prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    display(Markdown(content))\n",
    "else:\n",
    "    print(\"System prompt not found at prompts/pm_base.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d9ac0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Output\n",
    "\n",
    "Here's an example of an investment report generated through the workflow. Your output will be written to the `outputs` folder in the directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f0011",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to expand Investment Memo</summary>\n",
    "\n",
    "# Investment Memo: Alphabet Inc. (GOOGL) â€“ Impact of Planned Interest Rate Reduction (May 2025)\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "Alphabet Inc. (GOOGL) currently trades at \\$171.42 per share, with a market capitalization of \\$1.88 trillion and a P/E ratio of 16.91. The investment thesis is moderately constructive: while a planned interest rate reduction by the Federal Reserve is a mild tailwind, it is not the primary driver of GOOGL's price action. The most original, differentiated insightâ€”fully aligned with our firm's visionâ€”is that GOOGL's direct sensitivity to interest rates is modest (max weekly correlation with 10Y yield is ~0.29), and the real risk/reward hinges on the sustainability of AI-driven growth, sector rotation, and regulatory headwinds. This thesis is supported by robust technicals, strong fundamentals, and overwhelmingly positive analyst sentiment, but is tempered by the risk that AI optimism fades or macro/regulatory shocks emerge. The consensus view is justified by evidence: GOOGL's business remains resilient, but the variant viewâ€”where rate cuts fail to stimulate tech or sector rotation caps returnsâ€”should not be ignored. Key risks include regulatory action, macroeconomic uncertainty, and the potential for a shift in the AI narrative. In the best case, GOOGL could reach \\$200â€“\\$210 by year-end 2025; in the worst case, a retest of \\$160â€“\\$170 is plausible. This memo embodies the firm's vision by focusing on scenario planning, original quantitative analysis, and a critical assessment of consensus and variant views.\n",
    "\n",
    "## Fundamentals Perspective\n",
    "\n",
    "Alphabet's core business is driven by its dominance in digital advertising (Google Search, YouTube) and its growing cloud and AI segments. As of the latest quarter (Q1 2025), revenue was \\$90.2 billion, net income \\$34.5 billion, and EPS \\$2.81, with net margin at 38.3%. Margins have improved over the past year, and the company's scale and leadership in AI and cloud provide a durable moat. However, recent analyst price targets have been revised downward (Bernstein: \\$165, UBS: \\$209, Wolfe: \\$210), reflecting caution around regulatory and macroeconomic risks. The consensus view is justified: while Alphabet's financial strength and innovation are clear, regulatory scrutiny and macro headwinds (e.g., reduced ad budgets in downturns) are real risks. The most original insight is the company's ability to adapt and innovate, potentially mitigating some risks. The analysis is evidence-based, with recent quarterly data showing stable or improving margins:\n",
    "\n",
    "| Date       |    Revenue |   Net Income |   Gross Profit |   Total Expenses |   EPS |   Net Margin (%) |   Gross Margin (%) |   Operating Margin (%) |\n",
    "|:-----------|-----------:|-------------:|---------------:|-----------------:|------:|-----------------:|-------------------:|-----------------------:|\n",
    "| 2025-03-31 | 9.0234e+10 |   3.454e+10  |     5.3873e+10 |       5.9628e+10 |  2.81 |          38.28 |            59.70 |                33.92 |\n",
    "| 2024-12-31 | 9.6469e+10 |   2.6536e+10 |     5.5856e+10 |       6.5497e+10 |  2.15 |          27.51 |            57.90 |                32.11 |\n",
    "| 2024-09-30 | 8.8268e+10 |   2.6301e+10 |     5.1794e+10 |       5.9747e+10 |  2.12 |          29.80 |            58.68 |                32.31 |\n",
    "| 2024-06-30 | 8.4742e+10 |   2.3619e+10 |     4.9235e+10 |       5.7317e+10 |  1.89 |          27.87 |            58.10 |                32.36 |\n",
    "| 2024-03-31 | 8.0539e+10 |   2.3662e+10 |     4.6827e+10 |       5.5067e+10 |  1.89 |          29.38 |            58.14 |                31.63 |\n",
    "\n",
    "Recent analyst sentiment is overwhelmingly positive, with 56 Buy, 12 Hold, and 0 Sell recommendations currently:\n",
    "\n",
    "| period       |   Buy |   Hold |   Sell |\n",
    "|:-------------|------:|-------:|-------:|\n",
    "| Current      |    56 |     12 |      0 |\n",
    "| 1 Month Ago  |    55 |     12 |      0 |\n",
    "| 2 Months Ago |    55 |     12 |      0 |\n",
    "| 3 Months Ago |    53 |     12 |      0 |\n",
    "\n",
    "The fundamental view is aligned with the firm vision by focusing on evidence, scenario planning, and not simply following consensus. The main divergence from the firm vision would be if the analysis failed to consider the impact of regulatory or macro shocks, but this is addressed here.\n",
    "\n",
    "## Macro Perspective\n",
    "\n",
    "The macroeconomic environment is mixed. U.S. real GDP is expanding (\\$23.5 trillion, Q1 2025), unemployment is low (4.2%), and inflation remains elevated (CPI: 320.3). The Federal Reserve has kept rates at 4.25â€“4.50%, with a patient stance and a focus on evolving risks. The U.S. dollar is strong (DXY: 123.4), and recent tariffs have introduced uncertainty. Investors are rotating from U.S. tech to Asian equities, reflecting concerns about high valuations and better growth prospects abroad. The consensus macro view is that rate cuts will support tech valuations, but the variant viewâ€”supported by our firm's visionâ€”is that sector rotation and trade policy could offset these benefits. Tail-risk scenarios include a base case where rate cuts support GOOGL (\\$180â€“\\$190 target), and a downside where trade tensions or sector rotation cap returns. The analysis is evidence-based, using FRED data and recent policy statements, and explicitly considers both best- and worst-case scenarios. The macro view is fully aligned with the firm vision by challenging consensus and planning for multiple outcomes.\n",
    "\n",
    "## Quantitative Perspective\n",
    "\n",
    "Quantitative analysis confirms that GOOGL's direct sensitivity to interest rates is modest. The mean weekly correlation with the 10Y Treasury yield is 0.29, and with the Fed Funds rate is 0.05, indicating that rate changes are not the primary driver of GOOGL's returns. Technicals are robust: GOOGL is above key moving averages, momentum is positive, and volatility is moderate. Scenario analysis shows that a rate cut is a mild tailwind, but if the move is already priced in or if technicals break down, a 5â€“10% pullback is possible. Analyst sentiment is strongly positive, and fundamentals (revenue, margins) are improving. Quantitative summary statistics:\n",
    "\n",
    "| Metric                                  |     Value |\n",
    "|:----------------------------------------|----------:|\n",
    "| Mean daily corr (FEDFUNDS, GOOGL)       | 0.05 |\n",
    "| Mean daily reg slope (FEDFUNDS, GOOGL)  | 0.02 |\n",
    "| Mean daily corr (DGS10, GOOGL)          | 0.13 |\n",
    "| Mean daily reg slope (DGS10, GOOGL)     | 0.05 |\n",
    "| Mean weekly corr (FEDFUNDS, GOOGL)      | 0.05 |\n",
    "| Mean weekly reg slope (FEDFUNDS, GOOGL) | 0.03 |\n",
    "| Mean weekly corr (DGS10, GOOGL)         | 0.29 |\n",
    "| Mean weekly reg slope (DGS10, GOOGL)    | 0.09 |\n",
    "\n",
    "Key charts and images:\n",
    "\n",
    "![GOOGL Daily Returns](../../../images/multi_agent_collab_googl_daily_returns.png)\n",
    "![GOOGL Moving Averages](../../../images/multi_agent_collab_googl_moving_averages.png)\n",
    "![GOOGL RSI](../../../images/multi_agent_collab_googl_rsi.png)\n",
    "![GOOGL Rolling Volatility](../../../images/multi_agent_collab_googl_rolling_volatility.png)\n",
    "![Cumulative Return Comparison](../../../images/multi_agent_collab_cumulative_return_comparison.png)\n",
    "![Rolling Volatility Comparison](../../../images/multi_agent_collab_rolling_volatility_comparison.png)\n",
    "![Rolling Corr/Reg Daily Fed Funds](../../../images/multi_agent_collab_rolling_corr_reg_daily_fedfunds.png)\n",
    "![Rolling Corr/Reg Daily 10Y](../../../images/multi_agent_collab_rolling_corr_reg_daily_dgs10.png)\n",
    "![Rolling Corr/Reg Weekly Fed Funds](../../../images/multi_agent_collab_rolling_corr_reg_weekly_fedfunds.png)\n",
    "![Rolling Corr/Reg Weekly 10Y](../../../images/multi_agent_collab_rolling_corr_reg_weekly_dgs10.png)\n",
    "![GOOGL Quarterly Trends](../../../images/multi_agent_collab_GOOGL_quarterly_trends.png)\n",
    "![GOOGL Quarterly Margins](../../../images/multi_agent_collab_GOOGL_quarterly_margins.png)\n",
    "![GOOGL Analyst Recommendations Trend](../../../images/multi_agent_collab_GOOGL_analyst_recommendations_trend.png)\n",
    "\n",
    "The quantitative view is original in its focus on scenario analysis and the modest rate sensitivity, and is aligned with the firm vision by not simply following consensus. Limitations include the short post-pandemic data window and the fact that GOOGL's price is driven by multiple factors (AI, ad market, regulation) beyond rates.\n",
    "\n",
    "## Portfolio Manager Perspective\n",
    "\n",
    "The PM synthesis is that all three specialist sections converge on a moderately constructive outlook, with a realistic year-end 2025 price target of \\$190â€“\\$210. The most original insight is that GOOGL's direct rate sensitivity is modest, and the real risk is whether AI-driven growth can continue or if sector rotation and regulatory headwinds will cap returns. The quant section is strong in highlighting robust technicals and sentiment, but also the risk of a \\$160â€“\\$170 retest in downside scenarios. The fundamental and macro sections emphasize the importance of monitoring regulatory and trade policy. If underweight large-cap tech, now is a reasonable entry point, but position sizing should reflect the risk of sector rotation or macro disappointment. The variant viewâ€”rate cuts failing to stimulate tech or a shift in AI narrativeâ€”should not be ignored. Position sizing and risk management are key, fully in line with the firm's vision of scenario planning and differentiated insight.\n",
    "\n",
    "## Recommendation & Answer to the Question\n",
    "\n",
    "The recommendation is to maintain or modestly increase exposure to GOOGL, especially if underweight large-cap tech, with a year-end 2025 price target of \\$200â€“\\$210 in the base case. This embodies the firm vision by focusing on original, evidence-based scenario analysis, not simply following consensus. The recommendation is justified by robust fundamentals, positive technicals, and strong analyst sentiment, but is tempered by the risk of sector rotation, regulatory action, or a shift in the AI narrative. If these risks materialize, a retest of \\$160â€“\\$170 is possible. Sizing and risk management should reflect these scenarios. This approach is differentiated, evidence-driven, and fully aligned with the firm's vision.\n",
    "\n",
    "**END_OF_MEMO**\n",
    "\n",
    "*DISCLAIMER: I am an AI language model, not a registered investment adviser. Information provided is educational and general in nature. Consult a qualified financial professional before making any investment decisions.*\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290742f",
   "metadata": {},
   "source": [
    "\n",
    "## Best Practices When Building Agents\n",
    "\n",
    "The most effective agentic systems combine modular agent design, clear tool definitions, parallel execution, and structured prompts. This approachâ€”central to the OpenAI Agents SDKâ€”makes your workflows robust, scalable, and easy to debug or extend.\n",
    "\n",
    "**Key features of the OpenAI Agents SDK that enable these best practices:**\n",
    "- **Agent loop:** Handles tool calls, LLM reasoning, and workflow control automatically.\n",
    "- **Python-first orchestration:** Use familiar Python patterns to chain, compose, and orchestrate agents.\n",
    "- **Handoffs:** Delegate tasks between agents for specialization and modularity.\n",
    "- **Guardrails:** Validate inputs/outputs and break early on errors for reliability.\n",
    "- **Function tools:** Register any Python function as a tool, with automatic schema and validation.\n",
    "- **Tracing:** Visualize, debug, and monitor every step of your workflow for full transparency.\n",
    "\n",
    "A combination of well-designed tools, thoughtful orchestration, and careful model selection is crucial for building effective agent systems. In this example, we use the GPT-4.1 family of models for their strong analytical and tool-use capabilities ([see the GPT-4.1 Prompting Guide](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)). For deeper architectural best practices, see the included [A Practical Guide to Building Agents (PDF)](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf). By bringing these elements together, you get a system that is robust, scalable, and easy to debug or extend.\n",
    "\n",
    "Please try out the sample with your own investment questions, and please share any feedback! Happy building.\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading & Best Practices\n",
    "\n",
    "- [OpenAI Agents SDK Documentation](https://openai.github.io/openai-agents-python/)\n",
    "- [OpenAI Agents SDK: Multi-Agent Orchestration](https://openai.github.io/openai-agents-python/multi_agent/)\n",
    "- [OpenAI Agents SDK: Tool List](https://openai.github.io/openai-agents-python/tools/)\n",
    "- [OpenAI Agents SDK: MCP Documentation](https://openai.github.io/openai-agents-python/mcp/)\n",
    "\n",
    "- [MCP Spec](https://spec.modelcontextprotocol.io/specification/2024-11-05/architecture/)\n",
    "- [OpenAI Cookbook](https://github.com/openai/openai-cookbook)\n",
    "- ([GPT-4.1 Prompting Guide](https://cookbook.openai.com/examples/gpt4-1_prompting_guide))\n",
    "- [A Practical Guide to Building Agents (PDF)](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "playgroundenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
